# Copyright 2025 Pasteur Labs. All Rights Reserved.
# SPDX-License-Identifier: Apache-2.0

# Tesseract API module for {{name}}
# Generated by tesseract {{version}} on {{timestamp}}

from functools import partial
from typing import Any, Dict, List, Tuple, Callable

from pydantic import BaseModel
import torch
import numpy as np

from tesseract_core.runtime import Differentiable, Float32
from tesseract_core.runtime.tree_transforms import filter_func, flatten_with_paths

#
# Schemata
#


class InputSchema(BaseModel):
    example: Differentiable[Float32]


class OutputSchema(BaseModel):
    example: Differentiable[Float32]


#
# Required endpoints
#


# TODO: Add or import your function here, must differenciable and
# take/return a single pytree as an input/output conforming respectively
# to Input/OutputSchema
@torch.jit.script
def my_function(inputs: Any) -> Any:
    return inputs


# def parse_dict()


def apply(inputs: InputSchema) -> OutputSchema:
    # Convert to pytorch tensors to enable torch.jit
    inputs = convert_to_tensors(inputs.model_dump())

    # Optional: Insert any pre-processing/setup that doesn't require tracing
    # and is only required when specifically running your apply function
    # and not your differentiable endpoints.
    # For example, you might want to set up a logger or mlflow server.
    # Pre-processing should not modify any input that could impact the
    # differentiable outputs in a nonlinear way (a constant shift
    # should be safe)

    out = my_function(inputs)

    # Optional: Insert any post-processing that doesn't require tracing
    # For example, you might want to save to disk or modify a non-differentiable
    # output. Again, do not modify any differentiable output in a non-linear way.
    return out


#
# Pytorch-handled AD endpoints (no need to modify)
#


# def jacobian(
#     inputs: InputSchema,
#     jac_inputs: set[str],
#     jac_outputs: set[str],
# ):
#     # Convert to pytorch tensors to enable torch.jit and torch.autograd
#     inputs = convert_to_tensors(inputs.model_dump())

#     for key in jac_inputs:
#         inputs[key] = torch.nn.Parameter(inputs[key])

#     jac_result = {dy: {} for dy in jac_outputs}
#     with torch.enable_grad():
#         output = my_function(inputs)
       
#         grads = torch.autograd.grad(
#             output, inputs, retain_graph=True)[0]
        

        
#         # jac_result = grads

#     return jac_result


def jacobian(
    inputs: InputSchema,
    jac_inputs: set[str],
    jac_outputs: set[str],
):
    # Convert to pytorch tensors to enable torch.jit and torch.autograd
    inputs = convert_to_tensors(inputs.model_dump())

    for key in jac_inputs:
        inputs[key] = torch.nn.Parameter(inputs[key])

    jac_result = {dy: {} for dy in jac_outputs}
    with torch.enable_grad():
        output = my_function(inputs)
        for dx in jac_inputs:
            for dy in jac_outputs:
                grads = torch.autograd.grad(
                    output[dy], inputs[dx], retain_graph=True)[0]
                
                jac_result[dy][dx] = grads

    return jac_result


def jacobian_vector_product(
    inputs: InputSchema,
    jvp_inputs: set[str],
    jvp_outputs: set[str],
    tangent_vector: dict[str, Any],
):
    jacobian = jacobian(inputs, jvp_inputs, jvp_outputs)

    jvp_result = {dy: {} for dy in jvp_outputs}

    for dy in jvp_outputs:
        for dx in jvp_inputs:
            jvp_result[dy][dx] = torch.sum(
                jacobian[dy][dx] * tangent_vector[dx]
            )

    return jvp_result

def vector_jacobian_product(
    inputs: InputSchema,
    vjp_inputs: set[str],
    vjp_outputs: set[str],
    cotangent_vector: dict[str, Any],
):
    jacobian = jacobian(inputs, vjp_inputs, vjp_outputs)

    vjp_result = {dx: {} for dx in vjp_inputs}

    for dx in vjp_inputs:
        for dy in vjp_outputs:
            vjp_result[dx][dy] = torch.sum(
                jacobian[dy][dx] * cotangent_vector[dy]
            )

    return vjp_result


def convert_to_tensors(data):
    if isinstance(data, np.ndarray):
        return torch.from_numpy(data)
    elif isinstance(data, (np.floating, float)):
        return torch.tensor(data)
    elif isinstance(data, (np.integer, int)):
        return torch.tensor(data)
    elif isinstance(data, (np.bool_, bool)):
        return torch.tensor(data)
    elif isinstance(data, dict):
        return {key: convert_to_tensors(value) for key, value in data.items()}
    elif isinstance(data, list):
        return [convert_to_tensors(item) for item in data]
    else:
        raise TypeError(f"Unsupported data type: {type(data)}")