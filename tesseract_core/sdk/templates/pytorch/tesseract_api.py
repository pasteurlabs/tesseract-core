# Copyright 2025 Pasteur Labs. All Rights Reserved.
# SPDX-License-Identifier: Apache-2.0

# Tesseract API module for {{name}}
# Generated by tesseract {{version}} on {{timestamp}}

from typing import Any

import numpy as np
import torch
from pydantic import BaseModel
from torch.utils._pytree import tree_map

from tesseract_core.runtime import Differentiable, Float32
from tesseract_core.runtime.tree_transforms import filter_pos_func, flatten_with_paths

#
# Schemata
#


class InputSchema(BaseModel):
    example: Differentiable[Float32]


class OutputSchema(BaseModel):
    example: Differentiable[Float32]


#
# Required endpoints
#


# TODO: Add or import your function here, must be differentiable and
# take/return a single pytree as an input/output conforming respectively
# to Input/OutputSchema
def evaluate(inputs: Any) -> Any:
    print(inputs)
    return {
        "example": inputs["example"] + inputs["b"],
        "c": inputs["example"] * inputs["b"],
    }


def apply(inputs: InputSchema) -> OutputSchema:
    # Optional: Insert any pre-processing/setup that doesn't require tracing
    # and is only required when specifically running your apply function
    # and not your differentiable endpoints.
    # For example, you might want to set up a logger or mlflow server.
    # Pre-processing should not modify any input that could impact the
    # differentiable outputs in a nonlinear way (a constant shift
    # should be safe)

    # Convert to pytorch tensors
    inputs = tree_map(convert_to_tensors, inputs.model_dump())

    out = evaluate(inputs)

    # Optional: Insert any post-processing that doesn't require tracing
    # For example, you might want to save to disk or modify a non-differentiable
    # output. Again, do not modify any differentiable output in a non-linear way.
    return out


#
# Pytorch-handled AD endpoints (no need to modify)
#


def jacobian(
    inputs: InputSchema,
    jac_inputs: set[str],
    jac_outputs: set[str],
):
    # convert all numbers and arrays to torch tensors
    tensor_inputs = tree_map(convert_to_tensors, inputs.model_dump())

    # flatten the dictionaries such that they can be accessed by paths
    path_inputs = flatten_with_paths(tensor_inputs, jac_inputs)

    # transform the dictionaries into a list of values for a positional function
    pos_inputs = path_inputs.values()
    keys = path_inputs.keys()

    # create a positional function that accepts a list of values and returns a set of tuples
    filtered_pos_eval = filter_pos_func(
        evaluate, tensor_inputs, jac_outputs, keys, True
    )

    # calculate the jacobian
    jacobian = torch.autograd.functional.jacobian(filtered_pos_eval, tuple(pos_inputs))

    # rebuild the dictionary from the list of results
    res_dict = {}
    for dy, dys in zip(jac_outputs, jacobian):
        res_dict[dy] = {}
        for dx, dxs in zip(jac_inputs, dys):
            res_dict[dy][dx] = dxs

    return res_dict


def jacobian_vector_product(
    inputs: InputSchema,
    jvp_inputs: set[str],
    jvp_outputs: set[str],
    tangent: dict[str, Any],
):
    # convert all numbers and arrays to torch tensors
    tensor_inputs = tree_map(convert_to_tensors, inputs.model_dump())
    tensor_tangent = tree_map(convert_to_tensors, tangent)

    # flatten the dictionaries such that they can be accessed by paths
    path_inputs = flatten_with_paths(tensor_inputs, jvp_inputs)

    # transform the dictionaries into a list of values for a positional function
    pos_inputs = path_inputs.values()
    keys_inputs = path_inputs.keys()

    pos_tangent = tensor_tangent.values()

    # create a positional function that accepts a list of values
    filtered_pos_eval = filter_pos_func(
        evaluate, tensor_inputs, jvp_outputs, keys_inputs
    )

    tangent = torch.func.jvp(filtered_pos_eval, tuple(pos_inputs), tuple(pos_tangent))

    return tangent[1]


def vector_jacobian_product(
    inputs: InputSchema,
    vjp_inputs: set[str],
    vjp_outputs: set[str],
    cotangent_vector: dict[str, Any],
):
    # Make ordering of vjp in and output args deterministic
    # Necessacy as torch.vjp function requires inputs and outputs to be in the same order
    cotangent_vector = {key: cotangent_vector[key] for key in vjp_outputs}

    # convert all numbers and arrays to torch tensors
    tensor_inputs = tree_map(convert_to_tensors, inputs.model_dump())
    tensor_cotangent = tree_map(convert_to_tensors, cotangent_vector)

    # flatten the dictionaries such that they can be accessed by paths
    path_inputs = flatten_with_paths(tensor_inputs, vjp_inputs)

    # transform the dictionaries into a list of values for a positional function
    pos_inputs = path_inputs.values()
    keys_inputs = path_inputs.keys()

    # create a positional function that accepts a list of values
    filtered_pos_func = filter_pos_func(
        evaluate, tensor_inputs, vjp_outputs, keys_inputs
    )

    _, vjp_func = torch.func.vjp(filtered_pos_func, *pos_inputs)

    res = vjp_func(tensor_cotangent)

    # rebuild the dictionary from the list of results
    res_dict = {}
    for key, value in zip(vjp_inputs, res):
        res_dict[key] = value

    return res_dict


def convert_to_tensors(data):
    """Convert all numbers and arrays to torch tensors."""
    if isinstance(data, np.ndarray):
        return torch.from_numpy(data.copy())
    elif isinstance(data, (np.floating, float)):
        return torch.tensor(data)
    elif isinstance(data, (np.integer, int)):
        return torch.tensor(data)
    elif isinstance(data, (np.bool_, bool)):
        return torch.tensor(data)
    else:
        raise TypeError(f"Unsupported data type: {type(data)}")
